{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 198,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.050505050505050504,
      "grad_norm": 6.902083396911621,
      "learning_rate": 4.9242424242424245e-05,
      "loss": 2.6847,
      "step": 5
    },
    {
      "epoch": 0.10101010101010101,
      "grad_norm": NaN,
      "learning_rate": 4.797979797979798e-05,
      "loss": 2.1347,
      "step": 10
    },
    {
      "epoch": 0.15151515151515152,
      "grad_norm": 5.1279520988464355,
      "learning_rate": 4.696969696969697e-05,
      "loss": 2.0681,
      "step": 15
    },
    {
      "epoch": 0.20202020202020202,
      "grad_norm": 5.031994342803955,
      "learning_rate": 4.5707070707070706e-05,
      "loss": 1.4983,
      "step": 20
    },
    {
      "epoch": 0.25252525252525254,
      "grad_norm": 6.676203727722168,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 1.481,
      "step": 25
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 5.15327787399292,
      "learning_rate": 4.318181818181819e-05,
      "loss": 1.2366,
      "step": 30
    },
    {
      "epoch": 0.35353535353535354,
      "grad_norm": 6.874534606933594,
      "learning_rate": 4.191919191919192e-05,
      "loss": 1.4285,
      "step": 35
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 6.541738986968994,
      "learning_rate": 4.065656565656566e-05,
      "loss": 1.1861,
      "step": 40
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 6.056935787200928,
      "learning_rate": 3.939393939393939e-05,
      "loss": 1.2894,
      "step": 45
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 6.652664661407471,
      "learning_rate": 3.8131313131313133e-05,
      "loss": 1.1469,
      "step": 50
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 5.279499053955078,
      "learning_rate": 3.686868686868687e-05,
      "loss": 1.0244,
      "step": 55
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 5.128208160400391,
      "learning_rate": 3.560606060606061e-05,
      "loss": 0.8766,
      "step": 60
    },
    {
      "epoch": 0.6565656565656566,
      "grad_norm": 4.6867570877075195,
      "learning_rate": 3.434343434343435e-05,
      "loss": 0.8909,
      "step": 65
    },
    {
      "epoch": 0.7070707070707071,
      "grad_norm": 4.328650951385498,
      "learning_rate": 3.308080808080809e-05,
      "loss": 0.858,
      "step": 70
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 5.9715495109558105,
      "learning_rate": 3.181818181818182e-05,
      "loss": 0.8456,
      "step": 75
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 6.200254440307617,
      "learning_rate": 3.080808080808081e-05,
      "loss": 1.0053,
      "step": 80
    },
    {
      "epoch": 0.8585858585858586,
      "grad_norm": 8.90824031829834,
      "learning_rate": 2.954545454545455e-05,
      "loss": 0.8693,
      "step": 85
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 3.7412803173065186,
      "learning_rate": 2.8282828282828282e-05,
      "loss": 0.7252,
      "step": 90
    },
    {
      "epoch": 0.9595959595959596,
      "grad_norm": 3.959519147872925,
      "learning_rate": 2.7020202020202022e-05,
      "loss": 0.9401,
      "step": 95
    },
    {
      "epoch": 1.0101010101010102,
      "grad_norm": 4.864669322967529,
      "learning_rate": 2.575757575757576e-05,
      "loss": 0.7696,
      "step": 100
    },
    {
      "epoch": 1.0606060606060606,
      "grad_norm": 3.8238484859466553,
      "learning_rate": 2.4494949494949495e-05,
      "loss": 0.8825,
      "step": 105
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 3.899456024169922,
      "learning_rate": 2.3232323232323232e-05,
      "loss": 0.8668,
      "step": 110
    },
    {
      "epoch": 1.1616161616161615,
      "grad_norm": 6.431705951690674,
      "learning_rate": 2.1969696969696972e-05,
      "loss": 0.8118,
      "step": 115
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 6.267067909240723,
      "learning_rate": 2.070707070707071e-05,
      "loss": 0.7015,
      "step": 120
    },
    {
      "epoch": 1.2626262626262625,
      "grad_norm": 3.2339425086975098,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 0.674,
      "step": 125
    },
    {
      "epoch": 1.3131313131313131,
      "grad_norm": 4.285247325897217,
      "learning_rate": 1.8434343434343433e-05,
      "loss": 0.8856,
      "step": 130
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 7.005417346954346,
      "learning_rate": 1.7171717171717173e-05,
      "loss": 0.8576,
      "step": 135
    },
    {
      "epoch": 1.4141414141414141,
      "grad_norm": 5.140578269958496,
      "learning_rate": 1.590909090909091e-05,
      "loss": 0.7987,
      "step": 140
    },
    {
      "epoch": 1.4646464646464645,
      "grad_norm": 4.106833457946777,
      "learning_rate": 1.4646464646464647e-05,
      "loss": 0.7045,
      "step": 145
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 4.7382402420043945,
      "learning_rate": 1.3383838383838385e-05,
      "loss": 0.7862,
      "step": 150
    },
    {
      "epoch": 1.5656565656565657,
      "grad_norm": 5.260377883911133,
      "learning_rate": 1.2121212121212122e-05,
      "loss": 0.6379,
      "step": 155
    },
    {
      "epoch": 1.6161616161616161,
      "grad_norm": 5.269252777099609,
      "learning_rate": 1.085858585858586e-05,
      "loss": 0.8352,
      "step": 160
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 6.789454936981201,
      "learning_rate": 9.595959595959595e-06,
      "loss": 0.6549,
      "step": 165
    },
    {
      "epoch": 1.7171717171717171,
      "grad_norm": 6.799461841583252,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.8556,
      "step": 170
    },
    {
      "epoch": 1.7676767676767677,
      "grad_norm": 5.012114524841309,
      "learning_rate": 7.0707070707070704e-06,
      "loss": 0.6977,
      "step": 175
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 4.1752142906188965,
      "learning_rate": 5.808080808080808e-06,
      "loss": 0.5974,
      "step": 180
    },
    {
      "epoch": 1.8686868686868687,
      "grad_norm": 5.488881587982178,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 0.821,
      "step": 185
    },
    {
      "epoch": 1.9191919191919191,
      "grad_norm": 4.018186092376709,
      "learning_rate": 3.2828282828282835e-06,
      "loss": 0.6973,
      "step": 190
    },
    {
      "epoch": 1.9696969696969697,
      "grad_norm": 3.8492517471313477,
      "learning_rate": 2.0202020202020206e-06,
      "loss": 0.7427,
      "step": 195
    }
  ],
  "logging_steps": 5,
  "max_steps": 198,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4329247384535040.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
